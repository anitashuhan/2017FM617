{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 02 - No.8\n",
    "## 網路股票討論度與波動度關係之探討"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import json\n",
    "import jieba\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PTT_URL = 'https://www.ptt.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_web_page(url):\n",
    "    time.sleep(0.5)  # 每次爬取前暫停 0.5 秒以免被 PTT 網站判定為大量惡意爬取\n",
    "    resp = requests.get(url=url)\n",
    "    if resp.status_code != 200:\n",
    "        print('Invalid url:', resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_articles(dom, date):\n",
    "    soup = BeautifulSoup(dom, 'html.parser')\n",
    "\n",
    "    # 取得上一頁的連結\n",
    "    paging_div = soup.find('div', 'btn-group btn-group-paging')\n",
    "    prev_url = paging_div.find_all('a')[1]['href']\n",
    "\n",
    "    articles = []  # 儲存取得的文章資料\n",
    "    divs = soup.find_all('div', 'r-ent')\n",
    "    for d in divs:\n",
    "        if d.find('div', 'date').string.strip() == date:  # 發文日期正確\n",
    "            # 取得推文數\n",
    "            push_count = 0\n",
    "            if d.find('div', 'nrec').string:\n",
    "                try:\n",
    "                    push_count = int(d.find('div', 'nrec').string)  # 轉換字串為數字\n",
    "                except ValueError:  # 若轉換失敗，不做任何事，push_count 保持為 0\n",
    "                    pass\n",
    "\n",
    "            # 取得文章連結及標題\n",
    "            if d.find('a'):  # 有超連結，表示文章存在，未被刪除\n",
    "                href = d.find('a')['href']\n",
    "                title = d.find('a').string\n",
    "                articles.append(\n",
    "                    title,\n",
    "                )\n",
    "    return articles, prev_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(dom):\n",
    "    soup = BeautifulSoup(dom, 'html.parser')\n",
    "    links = soup.find(id='main-content').find_all('a')\n",
    "    img_urls = []\n",
    "    for link in links:\n",
    "        if re.match(r'^https?://(i.)?(m.)?imgur.com', link['href']):\n",
    "            img_urls.append(link['href'])\n",
    "    return img_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(img_urls, title):\n",
    "    if img_urls:\n",
    "        try:\n",
    "            dname = title.strip()  # 用 strip() 去除字串前後的空白\n",
    "            os.makedirs(dname)\n",
    "            for img_url in img_urls:\n",
    "                if img_url.split('//')[1].startswith('m.'):\n",
    "                    img_url = img_url.replace('//m.', '//i.')\n",
    "                if not img_url.split('//')[1].startswith('i.'):\n",
    "                    img_url = img_url.split('//')[0] + '//i.' + img_url.split('//')[1]\n",
    "                if not img_url.endswith('.jpg'):\n",
    "                    img_url += '.jpg'\n",
    "                fname = img_url.split('/')[-1]\n",
    "                urllib.request.urlretrieve(img_url, os.path.join(dname, fname))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    current_page = get_web_page(PTT_URL + '/bbs/Stock/index.html')\n",
    "    if current_page:\n",
    "        articles = []  # 全部的今日文章\n",
    "        date = time.strftime(\"01/02\").lstrip('0') # 今天日期, 去掉開頭的 '0' 以符合 PTT 網站格式\n",
    "        current_articles, prev_url = get_articles(current_page, date)  # 目前頁面的今日文章\n",
    "        while current_articles:  # 若目前頁面有今日文章則加入 articles，並回到上一頁繼續尋找是否有今日文章\n",
    "            articles += current_articles\n",
    "            current_page = get_web_page(PTT_URL + prev_url)\n",
    "            current_articles, prev_url = get_articles(current_page, date)\n",
    "            \n",
    "        # 已取得文章列表，開始進入各文章讀圖\n",
    "        \n",
    "        for article in articles:\n",
    "            print(article)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=jieba.analyse.extract_tags(str(articles),topK=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新聞/請益/標的/違反/板規/強勢/水桶/Re/蘋概/GIS/美律/權證/N5D6M6C/10/efun0242/一週/近幾年/積電/一樣/銀行/保險業/動作/判斷/匯率/走勢/友訊/2332/帶動/股價/漲停/type/台灣/有肉/世紀/9958/2395/研華/買到/樂透/什麼/財經/觀測站/著大/股東/進出/沒錯/進口車/進逼/u3000/執行長/凱泰/6462/神盾/16/大戶/領攻/11/000/宏達/12/月營/收僅/40/億元/創近/13/年次/公告/裕隆/利多/下周/布局/心情/真的/股票/可以\n"
     ]
    }
   ],
   "source": [
    "print(\"/\".join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
